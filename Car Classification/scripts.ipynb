{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDLr9rP7tTyh",
        "outputId": "e9b5fcbf-946d-4559-a89e-f5ad49f3c267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Copy image từ folder gốc qua drive riêng theo format folder của yolo/coco dataset"
      ],
      "metadata": {
        "id": "uYRzVugbSx1B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5amAE8JztPlG",
        "outputId": "c3737705-383f-4202-cbd4-bc3822a50391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing label: 0\n",
            "Copied 500 images for label: 0\n",
            "Processing label: 1\n",
            "Copied 500 images for label: 1\n",
            "Processing label: 2\n",
            "Copied 500 images for label: 2\n",
            "Processing label: 3\n",
            "Copied 500 images for label: 3\n",
            "Processing label: 4\n",
            "Copied 500 images for label: 4\n",
            "Processing label: 5\n",
            "Copied 500 images for label: 5\n",
            "Processing label: 6\n",
            "Copied 500 images for label: 6\n",
            "Processing label: 7\n",
            "Copied 500 images for label: 7\n",
            "Processing label: 8\n",
            "Copied 500 images for label: 8\n",
            "Data preparation completed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Paths and configurations\n",
        "csv_path = \"/content/UpdatedCarDataset.csv\"  # Replace with your CSV file path\n",
        "output_dir = \"/content/drive/MyDrive/yolov11_car\"\n",
        "old_path = \"/content/drive/MyDrive/Public\"  # Replace with your base path\n",
        "images_dir = os.path.join(output_dir, \"images\")\n",
        "train_test_split_ratio = 0.8\n",
        "images_per_label = 500\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(images_dir, exist_ok=True)\n",
        "\n",
        "# Read CSV file without headers\n",
        "df = pd.read_csv(csv_path, header=None, names=[\"path\", \"label\"])\n",
        "df['label'] = df['label'].astype(str)\n",
        "\n",
        "# Function to copy an image\n",
        "def copy_image(src, dest):\n",
        "    try:\n",
        "        if os.path.exists(src):\n",
        "            os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
        "            with open(src, \"rb\") as fsrc, open(dest, \"wb\") as fdest:\n",
        "                fdest.write(fsrc.read())\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to copy {src}: {e}\")\n",
        "    return False\n",
        "\n",
        "# Process each label\n",
        "for label in df['label'].unique():\n",
        "    print(f\"Processing label: {label}\")\n",
        "    label_df = df[df['label'] == label]\n",
        "    label_output_dir = os.path.join(images_dir, label)\n",
        "    os.makedirs(label_output_dir, exist_ok=True)\n",
        "\n",
        "    # Copy images for the label\n",
        "    copied_images = 0\n",
        "    for _, row in label_df.iterrows():\n",
        "        if copied_images >= images_per_label:\n",
        "            break\n",
        "        relative_path = row['path']\n",
        "        full_path = os.path.join(old_path, relative_path)  # Construct full path\n",
        "        output_path = os.path.join(label_output_dir, f\"{copied_images}.jpg\")\n",
        "        if copy_image(full_path, output_path):\n",
        "            copied_images += 1\n",
        "\n",
        "    print(f\"Copied {copied_images} images for label: {label}\")\n",
        "\n",
        "# Split into train and test datasets\n",
        "for label in os.listdir(images_dir):\n",
        "    label_path = os.path.join(images_dir, label)\n",
        "    images = os.listdir(label_path)\n",
        "    train, test = train_test_split(images, train_size=train_test_split_ratio, random_state=42)\n",
        "\n",
        "    # Create train/test directories\n",
        "    train_dir = os.path.join(output_dir, \"train\", label)\n",
        "    test_dir = os.path.join(output_dir, \"test\", label)\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    # Move files to train/test directories\n",
        "    for img in train:\n",
        "        os.rename(os.path.join(label_path, img), os.path.join(train_dir, img))\n",
        "    for img in test:\n",
        "        os.rename(os.path.join(label_path, img), os.path.join(test_dir, img))\n",
        "\n",
        "print(\"Data preparation completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lọc các ảnh bị lỗi và lưu các ảnh bình thường vào UpdatedCarDataset"
      ],
      "metadata": {
        "id": "lQzmDxx_T5ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "def filter_png_or_invalid_images(image_dir, csv_path):\n",
        "    # Load the CSV file\n",
        "    df = pd.read_csv(csv_path, header=None, names=[\"image_path\", \"label\"])\n",
        "\n",
        "    # Create a list to store valid rows\n",
        "    valid_rows = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        img_path = os.path.join(image_dir, row[\"image_path\"])\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                img.verify()  # Verify the image integrity\n",
        "                if img.format != 'PNG':  # Keep non-PNG valid images\n",
        "                    valid_rows.append(row)\n",
        "        except Exception:\n",
        "            # Skip rows corresponding to invalid images\n",
        "            pass\n",
        "\n",
        "    # Create a new DataFrame with valid rows\n",
        "    updated_df = pd.DataFrame(valid_rows, columns=[\"image_path\", \"label\"])\n",
        "    return updated_df\n",
        "\n",
        "# Example usage\n",
        "image_dir = \"/kaggle/input/car-brand/Public/Public\"  # Update this path\n",
        "csv_path = \"/kaggle/input/car-brand/CarDataset.csv\"  # Update this path\n",
        "\n",
        "updated_df = filter_png_or_invalid_images(image_dir, csv_path)\n",
        "\n",
        "# Display or save the DataFrame (optional)\n",
        "print(updated_df.head())\n",
        "# Optionally save to an output file in a writable directory\n",
        "# updated_df.to_csv(\"/kaggle/working/UpdatedCarDataset.csv\", header=False, index=False)\n"
      ],
      "metadata": {
        "id": "8cRRzmE2T2WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the updated DataFrame to a CSV file in a writable location\n",
        "output_csv_path = \"/kaggle/working/UpdatedCarDataset.csv\"\n",
        "updated_df.to_csv(output_csv_path, header=False, index=False)\n",
        "\n",
        "print(f\"Updated CSV saved to: {output_csv_path}\")"
      ],
      "metadata": {
        "id": "4PMm1mmOT415"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}